# Now let's load the COCO dataset
from torchvision.datasets import CocoDetection
import torchvision.transforms as transforms
from torch.utils.data import DataLoader

# Define transformations for preprocessing
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# Load COCO dataset
coco_train = CocoDetection(root='/content/coco_dataset/images/train2017', annFile='/content/coco_dataset/annotations/annotations/instances_train2017.json', transform=transform)
coco_val = CocoDetection(root='/content/coco_dataset/images/val2017', annFile='/content/coco_dataset/annotations/annotations/instances_val2017.json', transform=transform)

# Create DataLoader
batch_size = 8
train_loader = DataLoader(coco_train, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(coco_val, batch_size=batch_size, shuffle=False)

import os
import torch
import torchvision
from torchvision import transforms, datasets

# Define the dataset directory
data_dir = '/content/coco_dataset'

# Download and prepare the dataset
dataset = datasets.CocoDetection(root=data_dir, annFile=os.path.join(data_dir, '/content/coco_dataset/annotations/annotations/instances_train2017.json'),
                                 transform=transforms.ToTensor())

# Data loader
data_loader = torch.utils.data.DataLoader(dataset, batch_size=4, shuffle=True, num_workers=4)
import torchvision.models.detection as detection

# Load pre-trained Faster R-CNN model
model_faster_rcnn = detection.fasterrcnn_resnet50_fpn(pretrained=True)
model_faster_rcnn.eval()

# Move model to GPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model_faster_rcnn.to(device)
!git clone https://github.com/ultralytics/yolov5  # Clone YOLOv5 repository
%cd yolov5
%pip install -qr requirements.txt  # Install dependencies

import torch
# Load pre-trained YOLOv5 model
model_yolo = torch.hub.load('ultralytics/yolov5', 'yolov5s')
model_yolo.eval()
model_yolo.to(device)

##ssd model
model_ssd = detection.ssd300_vgg16(pretrained=True)
model_ssd.eval()
model_ssd.to(device)

model_retinanet = detection.retinanet_resnet50_fpn(pretrained=True)
model_retinanet.eval()
model_retinanet.to(device)

import os

# Define the base directory for the dataset
base_dir = '/content/coco_dataset'

# Define subdirectories for images and annotations
dirs = ['train', 'val', 'test']

for d in dirs:
    os.makedirs(os.path.join(base_dir, 'images', d), exist_ok=True)
    os.makedirs(os.path.join(base_dir, 'annotations', d), exist_ok=True)

import os
import json
from sklearn.model_selection import train_test_split
import shutil

# Define the base directory for the dataset
base_dir = '/content/coco_dataset'

# Define subdirectories for images and annotations
dirs = ['train', 'val', 'test']

for d in dirs:
    os.makedirs(os.path.join(base_dir, 'images', d), exist_ok=True)
    os.makedirs(os.path.join(base_dir, 'annotations', d), exist_ok=True)

# Define paths to the original COCO annotations
coco_annotations_path = os.path.join(base_dir, '/content/coco_dataset/annotations/annotations/instances_train2017.json')

# Load COCO annotations
with open(coco_annotations_path) as f:
    coco_data = json.load(f)

# Get image filenames and corresponding annotation IDs
image_ids = [img['id'] for img in coco_data['images']]
images_info = {img['id']: img for img in coco_data['images']}
annotations_info = {ann['image_id']: [] for ann in coco_data['annotations']}

for ann in coco_data['annotations']:
    annotations_info[ann['image_id']].append(ann)

# Split the dataset
train_ids, test_ids = train_test_split(image_ids, test_size=0.2, random_state=42)
train_ids, val_ids = train_test_split(train_ids, test_size=0.1, random_state=42)

# Helper function to save images and annotations
def save_split(ids, split_name):
    images_dir = os.path.join(base_dir, 'images', split_name)
    annotations_dir = os.path.join(base_dir, 'annotations', split_name)

    # Create COCO format annotation file
    split_annotations = {
        'images': [images_info[i] for i in ids],
        'annotations': [ann for i in ids if i in annotations_info for ann in annotations_info[i]],
        'categories': coco_data['categories']
    }

    with open(os.path.join(annotations_dir, f'instances_{split_name}.json'), 'w') as f:
        json.dump(split_annotations, f)

    # Copy images to the split directory
    for i in ids:
        img_info = images_info[i]
        img_filename = img_info['file_name']
        src_path = os.path.join(base_dir, 'images', 'train2017', img_filename)
        dst_path = os.path.join(images_dir, img_filename)
        if os.path.exists(src_path):  # Check if the image file exists before copying
            shutil.copy(src_path, dst_path)

# Save the training, validation, and test splits
save_split(train_ids, 'train')
save_split(val_ids, 'val')
save_split(test_ids, 'test')

import albumentations as A
from albumentations.pytorch import ToTensorV2
import cv2
import numpy as np
from google.colab.patches import cv2_imshow

# Define augmentation pipeline
transform = A.Compose([
    A.HorizontalFlip(p=0.5),
    A.RandomBrightnessContrast(p=0.2),
    A.Rotate(limit=15, p=0.5),
    A.Resize(512, 512),
    ToTensorV2()
], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels']))

# Example of applying transformations
def augment_image(image, bboxes, class_labels):
    transformed = transform(image=image, bboxes=bboxes, class_labels=class_labels)
    return transformed['image'], transformed['bboxes'], transformed['class_labels']


image = cv2.imread('/content/coco_dataset/images/test/000000000025.jpg')
bboxes = [[50, 30, 200, 150], [120, 80, 250, 180]]  # Example bounding boxes
class_labels = [1, 2]  # Example class labels

augmented_image, augmented_bboxes, augmented_class_labels = augment_image(image, bboxes, class_labels)

# Convert tensor to numpy array for visualization
augmented_image_np = augmented_image.permute(1, 2, 0).cpu().numpy()

# Display the augmented image using cv2_imshow
cv2_imshow(augmented_image_np)

!pip install torch torchvision torchaudio
!pip install tensorflow
!pip install opencv-python
!pip install albumentations

import torch
import torchvision.models.detection as detection

# Load pre-trained Faster R-CNN model
model_faster_rcnn = detection.fasterrcnn_resnet50_fpn(pretrained=True)
model_faster_rcnn.eval()

# Move model to GPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model_faster_rcnn.to(device)

import cv2
import torch
import torchvision
from torchvision.models.detection import FasterRCNN
from torchvision.models.detection.rpn import AnchorGenerator
from torchvision import transforms as T

# Load a pre-trained model on COCO
model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)
model.eval()

# Define the preprocessing transform
transform = T.Compose([
    T.ToPILImage(),
    T.ToTensor(),
    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])


image_path = '/content/coco_dataset/images/test/000000000042.jpg'
image = cv2.imread(image_path)
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
image_tensor = transform(image_rgb).unsqueeze(0)

# Perform inference
with torch.no_grad():
    output = model(image_tensor)

print(output)

# Clone YOLOv5 repository
!git clone https://github.com/ultralytics/yolov5
%cd yolov5
%pip install -qr requirements.txt  # Install dependencies

import torch

# Define the device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Load pre-trained YOLOv5 model
model_yolo = torch.hub.load('ultralytics/yolov5', 'yolov5s')
model_yolo.eval()
model_yolo.to(device)

# Clone the YOLOv5 repository and install requirements
!git clone https://github.com/ultralytics/yolov5
%cd yolov5
!pip install -r requirements.txt

# Training YOLOv5
!python train.py --img 640 --batch 16 --epochs 50 --data coco.yaml --weights yolov5s.pt

# Inference
!python detect.py --weights yolov5s.pt --img 640 --conf 0.25 --source path_to_image_or_video

# Load pre-trained SSD model
model_ssd = detection.ssd300_vgg16(pretrained=True)
model_ssd.eval()
model_ssd.to(device)

import cv2
import torch
import torchvision
from torchvision.models.detection import ssd300_vgg16
from torchvision import transforms as T

# Load a pre-trained model on COCO
model = ssd300_vgg16(pretrained=True)
model.eval()

# Define the preprocessing transform
transform = T.Compose([
    T.ToPILImage(),
    T.Resize((300, 300)),  # SSD300 expects images of size 300x300
    T.ToTensor(),
    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])


image_path = '/content/coco_dataset/images/train/000000000009.jpg'
image = cv2.imread(image_path)
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
image_tensor = transform(image_rgb).unsqueeze(0)

# Perform inference
with torch.no_grad():
    output = model(image_tensor)

print(output)

model_retinanet = detection.retinanet_resnet50_fpn(pretrained=True)
model_retinanet.eval()
model_retinanet.to(device)

import cv2
import torch
import torchvision
from torchvision.models.detection import retinanet_resnet50_fpn
from torchvision import transforms as T
from PIL import Image

# Load a pre-trained model on COCO
model = retinanet_resnet50_fpn(pretrained=True)
model.eval()

# Define the preprocessing transform
transform = T.Compose([
    T.Resize((800, 800)),  # Resize the image to a standard size
    T.ToTensor(),
    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])


image_path = '/content/coco_dataset/images/train2017/000000000034.jpg'
image = cv2.imread(image_path)
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# Apply the transform
image_pil = Image.fromarray(image_rgb)
image_tensor = transform(image_pil).unsqueeze(0)

# Perform inference
with torch.no_grad():
    output = model(image_tensor)

print(output)

def calculate_iou(box1, box2):
    # Calculate intersection
    xA = max(box1[0], box2[0])
    yA = max(box1[1], box2[1])
    xB = min(box1[2], box2[2])
    yB = min(box1[3], box2[3])
    interArea = max(0, xB - xA) * max(0, yB - yA)

    # Calculate union
    box1Area = (box1[2] - box1[0]) * (box1[3] - box1[1])
    box2Area = (box2[2] - box2[0]) * (box2[3] - box2[1])
    iou = interArea / float(box1Area + box2Area - interArea)
    return iou

import cv2
import torch
import torchvision
from torchvision.models.detection import retinanet_resnet50_fpn
from torchvision import transforms as T
from PIL import Image
import time

# Load a pre-trained model on COCO
model = retinanet_resnet50_fpn(pretrained=True)
model.eval()

# Define the preprocessing transform
transform = T.Compose([
    T.Resize((800, 800)),  # Resize the image to a standard size
    T.ToTensor(),
    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])


image_path = '/content/coco_dataset/images/train2017/000000000034.jpg'
image = cv2.imread(image_path)
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# Apply the transform
image_pil = Image.fromarray(image_rgb)
image_tensor = transform(image_pil).unsqueeze(0)

# Ensure the image is wrapped in a list
image_list = [image_tensor.squeeze(0)]

# Function to measure inference speed
def measure_inference_speed(model, image, iterations=100):
    # Warm-up run
    model(image)

    # Measure time
    start = time.time()
    for _ in range(iterations):
        model(image)
    end = time.time()

    avg_time = (end - start) / iterations
    return avg_time


avg_inference_time = measure_inference_speed(model, image_list)
print(f'Average inference time: {avg_inference_time} seconds')

import pandas as pd

# Placeholder values for IoU, mAP, and inference times
iou_faster_rcnn = 0.75
iou_yolov5 = 0.70
iou_ssd = 0.65
iou_retinanet = 0.68

map_faster_rcnn = 0.50
map_yolov5 = 0.55
map_ssd = 0.45
map_retinanet = 0.52

time_faster_rcnn = 0.10
time_yolov5 = 0.05
time_ssd = 0.08
time_retinanet = 0.09

# Store the results in a dictionary
results = {
    'Model': ['Faster R-CNN', 'YOLOv5', 'SSD', 'RetinaNet'],
    'IoU': [iou_faster_rcnn, iou_yolov5, iou_ssd, iou_retinanet],
    'mAP': [map_faster_rcnn, map_yolov5, map_ssd, map_retinanet],
    'Inference Time (s)': [time_faster_rcnn, time_yolov5, time_ssd, time_retinanet]
}

# Create a DataFrame from the results
df_results = pd.DataFrame(results)
print(df_results)





